{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_selection import GeneSift\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneSift Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, let's evaluate GeneSift's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data...\n",
    "\n",
    "# Read in the data (converting output label to binary).\n",
    "data = pd.read_csv(r'dry_bean_data.csv')\n",
    "data['Label'] = [int(data.iloc[i].Class == 'DERMASON') for i in range(len(data))]\n",
    "data = data.drop(columns=['Class'])\n",
    "\n",
    "# Seperate labels from predictors\n",
    "y = data['Label']\n",
    "X = data.drop(columns=['Label'])\n",
    "\n",
    "# Split the data into training and testing sets (arbitrarily an 80-20% split).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final fitness: 0.953168044077135\n"
     ]
    }
   ],
   "source": [
    "# EA parameters...\n",
    "# These are literally the first values we've tried. They seem to work fine.\n",
    "# Hence, there is plenty of room for experimentation!\n",
    "\n",
    "# Population size (i.e. the number of candidate solutions in each generation).\n",
    "pop_size = 50\n",
    "# Length of each candidate solution  (i.e. the number of features.)\n",
    "candidate_length = len(X.columns)\n",
    "# Limit on the number of generations to prevent excessive computation.\n",
    "gen_limit = 100\n",
    "# Size of the mating pool (must be even and smaller than pop_size).\n",
    "pool_size = 20\n",
    "# Size of the tournament for tournament selection (must be smaller than pool_size).\n",
    "tournament_size = 5\n",
    "# Crossover rate.\n",
    "crossover_rate = 0.9\n",
    "# Mutation rate.\n",
    "mutation_rate = 0.2\n",
    "# Threshold for improvement (used to decide when to terminate early).\n",
    "improve_threshold = 0.001\n",
    "\n",
    "# Instantiate a GeneSift selector.\n",
    "geneSift = GeneSift(pop_size, candidate_length, gen_limit, pool_size, tournament_size, crossover_rate, mutation_rate, improve_threshold)\n",
    "\n",
    "# Establish the data.\n",
    "geneSift.establish_data(X_train, y_train)\n",
    "\n",
    "# Find the optimal features.\n",
    "selection = geneSift.find_optimal_features()\n",
    "\n",
    "# Report the final fitness.\n",
    "print('Final fitness:', geneSift.fitness_function(selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features are selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [0] * 30\n",
    "algorithm_runs = 100\n",
    "\n",
    "for i in range(algorithm_runs):\n",
    "    selection = geneSift.find_optimal_features()\n",
    "\n",
    "    for j in range(candidate_length):\n",
    "        counts[j] += selection[j]\n",
    "\n",
    "probabilities = [count / algorithm_runs for count in counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44, 0.18, 0.42, 0.33, 0.49, 1.0, 0.4, 0.22, 0.49, 0.85, 0.97, 0.69, 0.31, 0.41, 0.5, 0.97, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pretty much at random', 'Almost never', 'Pretty much at random', 'Infrequently', 'Pretty much at random', 'Almost always', 'Pretty much at random', 'Infrequently', 'Pretty much at random', 'Almost always', 'Almost always', 'Frequently', 'Infrequently', 'Pretty much at random', 'Pretty much at random', 'Almost always', 'Almost never', 'Almost never', 'Almost never', 'Almost never', 'Almost never', 'Almost never', 'Almost never', 'Almost never', 'Almost never', 'Almost never', 'Almost never', 'Almost never', 'Almost never', 'Almost never']\n"
     ]
    }
   ],
   "source": [
    "interpretations = []\n",
    "for prob in probabilities:\n",
    "    if prob < 0.2:\n",
    "        interpretations.append('Almost never')\n",
    "    elif prob < 0.4:\n",
    "        interpretations.append('Infrequently')\n",
    "    elif prob <= 0.6:\n",
    "        interpretations.append('Pretty much at random')\n",
    "    elif prob < 0.8:\n",
    "        interpretations.append('Frequently')\n",
    "    else:\n",
    "        interpretations.append('Almost always')\n",
    "\n",
    "print(interpretations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Almost never count: 15\n",
      "Infrequently count: 3\n",
      "Pretty much at random count: 7\n",
      "Frequently count: 1\n",
      "Almost always count: 4\n"
     ]
    }
   ],
   "source": [
    "print('Almost never count:', len([i for i in interpretations if i == 'Almost never']))\n",
    "print('Infrequently count:', len([i for i in interpretations if i == 'Infrequently']))\n",
    "print('Pretty much at random count:', len([i for i in interpretations if i == 'Pretty much at random']))\n",
    "print('Frequently count:', len([i for i in interpretations if i == 'Frequently']))\n",
    "print('Almost always count:', len([i for i in interpretations if i == 'Almost always']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Other Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(X, y, selection):\n",
    "    # Cast the candidate solution to a boolean array.\n",
    "    selected_features = [bool(x) for x in selection]\n",
    "\n",
    "    # Our X and y are the selected features and the diagnosis.\n",
    "    X = X[X.columns[selected_features]]\n",
    "\n",
    "    # Split the data into training and testing sets (arbitrarily an 80-20% split).\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=0)\n",
    "\n",
    "    # Normlaise the data for numerical stability.\n",
    "    # We normalise after splitting to prevent data leakage.\n",
    "    ss_train = StandardScaler()\n",
    "    X_train = ss_train.fit_transform(X_train)\n",
    "\n",
    "    ss_test = StandardScaler()\n",
    "    X_test = ss_test.fit_transform(X_test)\n",
    "\n",
    "    # Define and train a logistic regression model.\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Determine the accuracy of the model (and hence the fitness of the candidate solution).\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness of GeneSift feature selection: 0.9588688946015425\n"
     ]
    }
   ],
   "source": [
    "# GeneSift selection's fitness...\n",
    "geneSift_fitness = evaluation(X, y, selection)\n",
    "print(\"Fitness of GeneSift feature selection:\", geneSift_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness of low variance feature selection: 0.937201615864855\n",
      "We improve on low variance feature selection by 2.312%.\n"
     ]
    }
   ],
   "source": [
    "# Low variance feature selection...\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "p = 0.8\n",
    "\n",
    "selection_lv = VarianceThreshold(threshold=p * (1 - p))\n",
    "selection_lv.fit_transform(X_train, y_train)\n",
    "selected_features = selection_lv.get_feature_names_out()\n",
    "\n",
    "# Convert this selection into a boolean array.\n",
    "low_variance_selection = []\n",
    "for feature in X.columns:\n",
    "    if feature in selected_features:\n",
    "        low_variance_selection.append(1)\n",
    "    else:\n",
    "        low_variance_selection.append(0)\n",
    "\n",
    "low_variance_fitness = evaluation(X, y, low_variance_selection)\n",
    "print(\"Fitness of low variance feature selection:\", low_variance_fitness) \n",
    "\n",
    "print(\"We improve on low variance feature selection by {}%.\".format(\n",
    "    round(((geneSift_fitness / low_variance_fitness) - 1) * 100, 3)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using k = 7\n",
      "Fitness of low variance feature selection: 0.9526257803892766\n",
      "We improve on low variance feature selection by 0.655%.\n"
     ]
    }
   ],
   "source": [
    "# Univariate feature selection...\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "k = len([1 for i in range(len(selection)) if selection[i] == 0])\n",
    "print('Using k =', k)\n",
    "\n",
    "# Make the selection.\n",
    "selection_u = SelectKBest(f_classif, k=k).fit_transform(X, y)\n",
    "\n",
    "univariate_selection = []\n",
    "for i in range(len(X.columns)):\n",
    "    column = data.iloc[:,i].values\n",
    "    \n",
    "    if column in selection_u.transpose():\n",
    "        univariate_selection.append(1)\n",
    "    else:\n",
    "        univariate_selection.append(0)\n",
    "\n",
    "univariate_fitness = evaluation(X, y, univariate_selection)\n",
    "print(\"Fitness of low variance feature selection:\", univariate_fitness) \n",
    "\n",
    "print(\"We improve on low variance feature selection by {}%.\".format(\n",
    "    round(((geneSift_fitness / univariate_fitness) - 1) * 100, 3)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using n = 7\n",
      "Fitness of RFE: 0.9460154241645244\n",
      "We improve on RFE by 1.359%.\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination (RFE)...\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "n = len([1 for i in range(len(selection)) if selection[i] == 0])\n",
    "print('Using n =', k)\n",
    "\n",
    "# Make the selection.\n",
    "selection_rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=n)\n",
    "selection_rfe.fit_transform(X, y)\n",
    "selected_features = selection_rfe.get_feature_names_out()\n",
    "\n",
    "# Convert this selection into a boolean array.\n",
    "rfe_selection = []\n",
    "for feature in X.columns:\n",
    "    if feature in selected_features:\n",
    "        rfe_selection.append(1)\n",
    "    else:\n",
    "        rfe_selection.append(0)\n",
    "\n",
    "rfe_fitness = evaluation(X, y, rfe_selection)\n",
    "print(\"Fitness of RFE:\", rfe_fitness) \n",
    "\n",
    "print(\"We improve on RFE by {}%.\".format(\n",
    "    round(((geneSift_fitness / rfe_fitness) - 1) * 100, 3)\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
